---
title: "[Mathematical Statistics] Chapter3"

categories:
  - Mathematical Statistics
tags:
  - [statistics]

layout: single_v2

permalink: /math_stat/ch3/
excerpt: "Chapter 3. Special Distributions"
last_modified_at: Now

toc: true
toc_sticky: true
---

# Bernoulli and Binomial

## Bernoulli distribution
Bernoulli experiment: a random experiment that outcome are classified with two mutually exclusive and exhaustive ways \\
Bernoulli process: a sequence of **Bernoulli trials**.

Let X be a random variable associated with a Bernoulli trial
1. The pmf of X is \\(p(x) = p^x(1-p)^{1-x}, x=0,1 \\)
2. The expected value is \\( E[X] = p \\)
3. The variance is \\( var(X) = p^2(1-p)+(1-p)^2p = p(1-p) \\)

## Binomial distribution
Binomial random variable $$X$$: $$X$$ = # of sucesses in $$n$$ Bernoulli trials, denoted by \\( b(n,p) \\)

1. The pmf of $$X$$ is $$p(x) = \binom{n}{x} p^x(1-p)^{n-x}, x=0,1,...,n$$
2. The mgf: $$\begin{aligned}[t]
    E(e^tX) &= \sum_{x=0}^{n}e^{tx} \binom{n}{x}p^x(1-p)^{n-x} \\ &= (1-p+pe^t)^n
    \end{aligned}$$
3. The mean and variances: $$E(X) = np,\ Var(X) = np(1-p) $$

### Therorem 3.1.1. sum of binomial distribution
Let independent random variable $$X_1,..,X_m$$ where $$X_i \sim b(n_i, p)\ for\ i=1,...,m$$. Then $$Y = \sum_{i=1}^{m}X_i$$ has a $$b(\sum_{i=1}^{m}n_i, p)$$ distribution

#### e.g. Joint distribution

## Negative Binomial distribution
Y denote the total number of failures in the sequence before $$r^{th}$$ success.

1. pmf: $$p(y) = \binom{y+r-1}{r-1}p^r(1-p)^y\, y=0,1...$$
2. mgf: $$M(t) = p^r(1-(1-p)e^t)^{-r}\ for\ t<-log(1-p)$$

## Geometric distribution
Y is a number of trials until a success \\
This is $$r=1$$ case of Negative Binomial distribution

1. pmf: $$p(y) = p(1-p)^y\, y=0,1,2,...$$
2. mfg: $$M(t) = p(1-(1-p)e^t)^{-1}$$

## Multi-nomial distribution
The experiments is held by $$k$$ mutually exclusive and exhaustive ways.

1. pmf: $$\frac{n!}{X_1! \cdots X_k!}p_1^{X_1}\cdots p_k^{X_k}$$ where $$X_k = n-(X_1+\cdots+X_{k-1})$$ and $$\sum_{i=1}^{k}p_i =1$$
2. mgf: $$M(t_1, ... , t_{k-1}) = (p_1e^{t_1}+ \cdots + P_{k-1}e^{t_{k-1}}+p_k)^n$$ for $$t_1, ... , t_{k-1} \in \mathbb{R}$$

## Hypergeometric distribution
Let N as number of items and D is a number of defective items amont them. Let X is a number of defective items in a sample of size n, without replacement.

1. pmf: $$p(x) = \frac{\binom{N-D}{n-x}\binom{D}{x}}{\binom{N}{n}}$$
